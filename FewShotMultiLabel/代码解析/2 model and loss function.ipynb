{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建与损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**目录：**\n",
    "1. FewShotMultiLabel模型： SchemaFewShotTextClassifier\n",
    "    - ContextEmbedder；\n",
    "    - emission scorer；\n",
    "    - similarity scorer;\n",
    "    - decoder；\n",
    "\n",
    "\n",
    "2. 损失函数计算\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContextEmbedder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基类\n",
    "class ContextEmbedderBase(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContextEmbedderBase, self).__init__()\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return: test_token_reps, support_token_reps, test_sent_reps, support_sent_reps\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 BERT 的上下文编码器\n",
    "\n",
    "class BertContextEmbedder(ContextEmbedderBase):\n",
    "    def __init__(self, opt):\n",
    "        super(BertContextEmbedder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.embedder = self.build_embedder()  # 加载BERT预训练模型\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_token_ids: torch.Tensor,\n",
    "            test_segment_ids: torch.Tensor,\n",
    "            test_nwp_index: torch.Tensor,\n",
    "            test_input_mask: torch.Tensor,\n",
    "            support_token_ids: torch.Tensor = None,\n",
    "            support_segment_ids: torch.Tensor = None,\n",
    "            support_nwp_index: torch.Tensor = None,\n",
    "            support_input_mask: torch.Tensor = None,\n",
    "    ) -> (torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        get context representation\n",
    "        :param test_token_ids: (batch_size, test_len)\n",
    "        :param test_segment_ids: (batch_size, test_len)\n",
    "        :param test_nwp_index: (batch_size, test_len, 1)\n",
    "        :param test_input_mask: (batch_size, test_len)\n",
    "\n",
    "        ======= Support features ======\n",
    "        We allow to only embed query to enable single sentence embedding, but such feature is NOT used now.\n",
    "        (Separate embedding is achieved through special sub classes)\n",
    "\n",
    "        :param support_token_ids: (batch_size, support_size, support_len)\n",
    "        :param support_segment_ids: (batch_size, support_size, support_len)\n",
    "        :param support_nwp_index: (batch_size, support_size, support_len, 1)\n",
    "        :param support_input_mask: (batch_size, support_size, support_len)\n",
    "        :return:\n",
    "            \n",
    "            # 如果没有support set，则只进行query的编码\n",
    "            if do concatenating representation:\n",
    "                return (test_reps, support_reps, test_sent_reps, support_sent_reps):\n",
    "                    test_reps, support_reps:  token reps (batch_size, support_size, nwp_sent_len, emb_len)\n",
    "                    test_sent_reps, support_sent_reps: sent reps (batch_size, support_size, 1, emb_len)\n",
    "            else do representation for a single sent (No support staff):\n",
    "                return test_reps, shape is (batch_size, nwp_sent_len, emb_len)\n",
    "        \"\"\"\n",
    "        if support_token_ids is not None:\n",
    "            return self.concatenate_reps(\n",
    "                test_token_ids, test_segment_ids, test_nwp_index, test_input_mask,\n",
    "                support_token_ids, support_segment_ids, support_nwp_index, support_input_mask,\n",
    "            )\n",
    "        else:\n",
    "            return self.single_reps(test_token_ids, test_segment_ids, test_nwp_index, test_input_mask,)\n",
    "\n",
    "    def build_embedder(self):\n",
    "        \"\"\" load bert here \"\"\"\n",
    "        return BertModel.from_pretrained(self.opt.bert_path)\n",
    "\n",
    "    def concatenate_reps(\n",
    "            self,\n",
    "            test_token_ids: torch.Tensor,\n",
    "            test_segment_ids: torch.Tensor,\n",
    "            test_nwp_index: torch.Tensor,\n",
    "            test_input_mask: torch.Tensor,\n",
    "            support_token_ids: torch.Tensor,\n",
    "            support_segment_ids: torch.Tensor,\n",
    "            support_nwp_index: torch.Tensor,\n",
    "            support_input_mask: torch.Tensor,\n",
    "    ) -> (torch.Tensor, torch.Tensor):\n",
    "        \"\"\" get token reps of a sent pair. \"\"\"\n",
    "        # support set 的 最大数量\n",
    "        support_size = support_token_ids.shape[1]\n",
    "        \n",
    "        # 序列长度\n",
    "        test_len = test_token_ids.shape[-1] - 2  # max len, exclude [CLS] and [SEP] token\n",
    "        support_len = support_token_ids.shape[-1] - 1  # max len, exclude [SEP] token\n",
    "        \n",
    "        # \n",
    "        batch_size = support_token_ids.shape[0]\n",
    "        \n",
    "        # 将query数据的形状更改\n",
    "        ''' expand test input to shape: (batch_size, support_size, test_len)'''\n",
    "        test_token_ids, test_segment_ids, test_input_mask, test_nwp_index = self.expand_test_item(\n",
    "            test_token_ids, test_segment_ids, test_input_mask, test_nwp_index, support_size)\n",
    "        \n",
    "        # 将query和每个support set样本拼接： concat操作，沿最后一个维度        \n",
    "        ''' concat test and support '''\n",
    "        input_ids = self.cat_test_and_support(test_token_ids, support_token_ids)\n",
    "        segment_ids = self.cat_test_and_support(test_segment_ids, support_segment_ids)\n",
    "        input_mask = self.cat_test_and_support(test_input_mask, support_input_mask)\n",
    "        \n",
    "        # 将 (batch_size, support_size, cat_len) 头两个维度合并，则为 (batch_size * support_size, sent_len)\n",
    "        ''' flatten input '''\n",
    "        input_ids, segment_ids, input_mask = self.flatten_input(input_ids, segment_ids, input_mask)\n",
    "        # 将 (batch_size, support_size, index_len, 1) 头两个维度合并，则为 (batch_size * support_size, index_len, 1)\n",
    "        test_nwp_index, support_nwp_index = self.flatten_index(test_nwp_index), self.flatten_index(support_nwp_index)\n",
    "        \n",
    "        # bert编码输入: (batch_size * support_size, sent_len, hidden_dim)\n",
    "        ''' get concat reps '''\n",
    "        sequence_output = self.embedder(input_ids, input_mask, segment_ids)[0]\n",
    "        \n",
    "        '''\n",
    "        torch.narrow(input, dim, start, length):\n",
    "            The dimension dim is input from start to start + length.\n",
    "        \n",
    "        '''\n",
    "        # 在序列长度这个维度，取出tensor的一部分\n",
    "        ''' extract reps '''\n",
    "        # select pure sent part, remove [SEP] and [CLS], notice: seq_len1 == seq_len2 == max_len.\n",
    "        test_reps = sequence_output.narrow(-2, 1, test_len)  # shape:(batch * support_size, test_len, rep_size)\n",
    "        support_reps = sequence_output.narrow(-2, 2 + test_len, support_len)  # shape:(batch * support_size, support_len, rep_size)\n",
    "        \n",
    "        # 取出wordpiece模型没有拆分的单词的表征\n",
    "        # test_reps： shape (batch_size * support_size, test_len, hidden_dim)\n",
    "        # test_nwp_index： shape (batch_size * support_size, index_len, 1)\n",
    "        # select non-word-piece tokens' representation\n",
    "        nwp_test_reps = self.extract_non_word_piece_reps(test_reps, test_nwp_index)\n",
    "        nwp_support_reps = self.extract_non_word_piece_reps(support_reps, support_nwp_index)\n",
    "        \n",
    "        # 改变形状\n",
    "        # resize to shape (batch_size, support_size, sent_len, emb_len)\n",
    "        reps_size = nwp_test_reps.shape[-1]\n",
    "        nwp_test_reps = nwp_test_reps.view(batch_size, support_size, -1, reps_size)\n",
    "        nwp_support_reps = nwp_support_reps.view(batch_size, support_size, -1, reps_size)\n",
    "        test_reps = test_reps.view(batch_size, support_size, -1, reps_size)\n",
    "        support_reps = support_reps.view(batch_size, support_size, -1, reps_size)\n",
    "        \n",
    "        # average pooling\n",
    "        # get whole sent reps\n",
    "        test_sent_reps = self.get_sent_reps(test_reps, test_input_mask)\n",
    "        support_sent_reps = self.get_sent_reps(support_reps, support_input_mask)\n",
    "        return nwp_test_reps, nwp_support_reps, test_sent_reps, support_sent_reps\n",
    "\n",
    "    def single_reps(\n",
    "            self,\n",
    "            test_token_ids: torch.Tensor,\n",
    "            test_segment_ids: torch.Tensor,\n",
    "            test_nwp_index: torch.Tensor,\n",
    "            test_input_mask: torch.Tensor,\n",
    "    ) -> (torch.Tensor, torch.Tensor):\n",
    "        \"\"\" get token reps of a single sent. \"\"\"\n",
    "        test_len = test_token_ids.shape[-1] - 2  # max len, exclude [CLS] and [SEP] token\n",
    "        batch_size = test_token_ids.shape[0]\n",
    "        ''' get bert reps '''\n",
    "        test_sequence_output = self.embedder(test_token_ids, test_input_mask, test_segment_ids)[0]\n",
    "        ''' extract reps '''\n",
    "        # select pure sent part, remove [SEP] and [CLS], notice: seq_len1 == seq_len2 == max_len.\n",
    "        test_reps = test_sequence_output.narrow(-2, 1, test_len)  # shape:(batch, test_len, rep_size)\n",
    "        # select non-word-piece tokens' representation\n",
    "        nwp_test_reps = self.extract_non_word_piece_reps(test_reps, test_nwp_index)\n",
    "        # get whole word reps, unsuqeeze to fit interface\n",
    "        test_sent_reps = self.get_sent_reps(test_reps.unsqueeze(1), test_input_mask.unsqueeze(1)).squeeze(1)\n",
    "        return nwp_test_reps, test_sent_reps\n",
    "\n",
    "    def get_sent_reps(self, reps, input_mask):\n",
    "        \"\"\"\n",
    "         Average token reps to get a whole sent reps\n",
    "        :param reps:   (batch_size, support_size, sent_len, emb_len)\n",
    "        :param input_mask:  (batch_size, support_size, sent_len)\n",
    "        :return:  averaged reps (batch_size, support_size, sent_len, emb_len)\n",
    "        \"\"\"\n",
    "        batch_size, support_size, sent_len, reps_size = reps.shape\n",
    "        mask_len = input_mask.shape[-1]\n",
    "        \n",
    "        # 因为是要取平均，所以要数出来具体的实际句长\n",
    "        # count each sent's tokens, to avoid over div with pad,  shape: (batch_size * support_size, 1)\n",
    "        token_counts = torch.sum(input_mask.contiguous().view(-1, mask_len), dim=1).unsqueeze(-1)\n",
    "        sp_token_num = input_mask.shape[-1] - reps.shape[-2]  # num of [CLS], [SEP] tokens\n",
    "        token_counts = token_counts - sp_token_num + 0.00001  # calculate pure token num and remove zero\n",
    "        \n",
    "        # mask pad-token's reps to 0 vectors [Notice that by default pad token's reps are not 0-vector]\n",
    "        # 去除BERT特殊符号对应的mask部分\n",
    "        if sp_token_num == 2:\n",
    "            trimed_mask = input_mask.narrow(-1, 1, reps.shape[-2]).float()  # remove mask of [CLS], [SEP]\n",
    "        elif sp_token_num == 1:\n",
    "            trimed_mask = input_mask.narrow(-1, 0, reps.shape[-2]).float()  # remove mask of [SEP]\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected sp_token_num.\")\n",
    "        \n",
    "        # 用mask把padding部分改为0，这样就不会影响最后的avg pooling\n",
    "        reps = reps * trimed_mask.unsqueeze(-1)\n",
    "        # sum reps, shape (batch_size * support_size, emb_len)\n",
    "        sum_reps = torch.sum(reps.contiguous().view(-1, sent_len, reps_size), dim=1)\n",
    "        # averaged reps (batch_size, support_size, emb_len)\n",
    "        ave_reps = torch.div(sum_reps, token_counts.float()).contiguous().view(batch_size, support_size, reps_size)\n",
    "        return ave_reps.unsqueeze(-2)\n",
    "\n",
    "    def expand_test_item(\n",
    "            self,\n",
    "            test_token_ids: torch.Tensor,\n",
    "            test_segment_ids: torch.Tensor,\n",
    "            test_input_mask: torch.Tensor,\n",
    "            test_nwp_index: torch.Tensor,\n",
    "            support_size: int,\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        # 在第一个维度位置增加一个维度\n",
    "        return self.expand_it(test_token_ids, support_size), self.expand_it(test_segment_ids, support_size), \\\n",
    "               self.expand_it(test_input_mask, support_size), self.expand_it(test_nwp_index, support_size)\n",
    "\n",
    "    def expand_it(self, item: torch.Tensor, support_size):\n",
    "        expand_shape = list(item.unsqueeze_(1).shape)\n",
    "        expand_shape[1] = support_size\n",
    "        \n",
    "        # tensor_.expand(shape): 扩大维度，但不增加内存消耗\n",
    "        return item.expand(expand_shape)\n",
    "\n",
    "    def cat_test_and_support(self, test_item, support_item):\n",
    "        return torch.cat([test_item, support_item], dim=-1)\n",
    "\n",
    "    def flatten_input(self, input_ids, segment_ids, input_mask):\n",
    "        \"\"\" resize shape (batch_size, support_size, cat_len) to shape (batch_size * support_size, sent_len) \"\"\"\n",
    "        sent_len = input_ids.shape[-1]\n",
    "        input_ids = input_ids.view(-1, sent_len)\n",
    "        segment_ids = segment_ids.view(-1, sent_len)\n",
    "        input_mask = input_mask.view(-1, sent_len)\n",
    "        return input_ids, segment_ids, input_mask\n",
    "\n",
    "    def flatten_index(self, nwp_index):\n",
    "        \"\"\" resize shape (batch_size, support_size, index_len, 1) to shape (batch_size * support_size, index_len, 1) \"\"\"\n",
    "        nwp_sent_len = nwp_index.shape[-2]\n",
    "        return nwp_index.contiguous().view(-1, nwp_sent_len, 1)\n",
    "\n",
    "    def extract_non_word_piece_reps(self, reps, index):\n",
    "        \"\"\"\n",
    "        Use the first word piece as entire word representation\n",
    "        As we have only one index for each token, we need to expand to the size of reps dim.\n",
    "        \"\"\"\n",
    "        expand_shape = list(index.shape)\n",
    "        expand_shape[-1] = reps.shape[-1]  # expend index over embedding dim, like 768\n",
    "        index = index.expand(expand_shape)\n",
    "        \n",
    "        nwp_reps = torch.gather(input=reps, index=index, dim=-2)  \n",
    "        # extract over token level\n",
    "        # 沿着句子序列维度，取向量\n",
    "        \n",
    "        return nwp_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSchemaContextEmbedder(BertContextEmbedder):\n",
    "    def __init__(self, opt):\n",
    "        super(BertSchemaContextEmbedder, self).__init__(opt)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_token_ids: torch.Tensor,\n",
    "            test_segment_ids: torch.Tensor,\n",
    "            test_nwp_index: torch.Tensor,\n",
    "            test_input_mask: torch.Tensor,\n",
    "            support_token_ids: torch.Tensor = None,\n",
    "            support_segment_ids: torch.Tensor = None,\n",
    "            support_nwp_index: torch.Tensor = None,\n",
    "            support_input_mask: torch.Tensor = None,\n",
    "            reps_type: str = 'test_support',\n",
    "    ) -> (torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        get context representation\n",
    "        :param test_token_ids: (batch_size, test_len)\n",
    "        :param test_segment_ids: (batch_size, test_len)\n",
    "        :param test_nwp_index: (batch_size, test_len, 1)\n",
    "        :param test_input_mask: (batch_size, test_len)\n",
    "        :param support_token_ids: (batch_size, support_size, support_len)\n",
    "        :param support_segment_ids: (batch_size, support_size, support_len)\n",
    "        :param support_nwp_index: (batch_size, support_size, support_len, 1)\n",
    "        :param support_input_mask: (batch_size, support_size, support_len)\n",
    "        :param reps_type: select the reps type, default: reps for test and support tokens. Special choice is for label\n",
    "        :return:\n",
    "            if do concatenating representation:\n",
    "                return (test_reps, support_reps, test_sent_reps, support_sent_reps):\n",
    "                    test_reps, support_reps:  token reps (batch_size, support_size, nwp_sent_len, emb_len)\n",
    "                    test_sent_reps, support_sent_reps: sent reps (batch_size, support_size, 1, emb_len)\n",
    "            else do representation for a single sent (No support staff):\n",
    "                return test_reps, shape is (batch_size, nwp_sent_len, emb_len)\n",
    "        \"\"\"\n",
    "        if reps_type == 'test_support':\n",
    "            if support_token_ids is not None:\n",
    "                return self.concatenate_reps(\n",
    "                    test_token_ids, test_segment_ids, test_nwp_index, test_input_mask,\n",
    "                    support_token_ids, support_segment_ids, support_nwp_index, support_input_mask,\n",
    "                )\n",
    "            else:\n",
    "                return self.single_reps(test_token_ids, test_segment_ids, test_nwp_index, test_input_mask,)\n",
    "        elif reps_type == 'label':\n",
    "            return self.get_label_reps(test_token_ids, test_segment_ids, test_nwp_index, test_input_mask)\n",
    "    \n",
    "    \n",
    "    # 这里主要关注 label_reps = “sep”的情形：\n",
    "    #     -- 就是我们常见的用BERT表征一个句子的流程：采用[CLS]的向量表征\n",
    "    def get_label_reps(self, test_token_ids, test_segment_ids, test_nwp_index, test_input_mask):\n",
    "        batch_size = test_token_ids.shape[0]\n",
    "        if self.opt.label_reps == 'cat':\n",
    "            # todo: use label mask to represent a label with only in domain info\n",
    "            reps = self.single_reps(test_token_ids, test_segment_ids, test_nwp_index, test_input_mask, )\n",
    "        elif self.opt.label_reps in ['sep', 'sep_sum']:\n",
    "            input_ids, segment_ids, input_mask = self.flatten_input(test_token_ids, test_segment_ids,\n",
    "                                                                    test_input_mask)\n",
    "            # get flatten reps: shape (batch_size * label_num, label_des_len)\n",
    "            sequence_output = self.embedder(input_ids, input_mask, segment_ids)[0]\n",
    "            reps_size = sequence_output.shape[-1]\n",
    "            if self.opt.label_reps == 'sep':  # use cls as each label's reps\n",
    "                # re-shape to  (batch_size, label_num, label_des_len)\n",
    "                reps = sequence_output.narrow(-2, 0, 1)  # fetch all [CLS] shape:(batch, 1, rep_size)\n",
    "                reps = reps.contiguous().view(batch_size, -1, reps_size)\n",
    "            elif self.opt.label_reps == 'sep_sum':  # average all label reps as reps\n",
    "                reps = sequence_output\n",
    "                emb_mask = self.expand_mask(test_input_mask, 2, reps_size)\n",
    "                # todo: use mask to get sum of single embedding\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                raise ValueError(\"Wrong label_reps choice \")\n",
    "        else:\n",
    "            raise ValueError(\"Wrong reps_type choice\")\n",
    "        return reps\n",
    "\n",
    "    def expand_mask(self, item: torch.Tensor, expand_size, dim):\n",
    "        new_item = item.unsqueeze(dim)\n",
    "        expand_shape = list(new_item.shape)\n",
    "        expand_shape[dim] = expand_size\n",
    "        return new_item.expand(expand_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-scale input tensor's value\n",
    "\n",
    "对输入向量大小进行缩放\n",
    "\n",
    "我们主要关注： emission_normalizer=None, emission_scaler=learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleControllerBase(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The base class for ScaleController.\n",
    "    ScaleController is a callable class that re-scale input tensor's value.\n",
    "    Traditional scale method may include:\n",
    "        soft-max, L2 normalize, relu and so on.\n",
    "    Advanced method:\n",
    "        Learnable scale parameter\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ScaleControllerBase, self).__init__()\n",
    "\n",
    "    def forward(self, x:  torch.Tensor, dim: int = 0, p: int = 1):\n",
    "        \"\"\"\n",
    "        Re-scale the input x into proper value scale.\n",
    "        :param x: the input tensor\n",
    "        :param dim: axis to scale(mostly used in traditional method)\n",
    "        :param p: p parameter used in traditional methods\n",
    "        :return: rescaled x\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnableScaleController(ScaleControllerBase):\n",
    "    \"\"\"\n",
    "    Scale parameter mentioned in [Tadam: Task dependent adaptive metric for improved few-shot learning. (NIPS2018)]\n",
    "    \"\"\"\n",
    "    def __init__(self, normalizer: ScaleControllerBase = None):\n",
    "        super(LearnableScaleController, self).__init__()\n",
    "        self.scale_rate = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "        self.normalizer = normalizer\n",
    "\n",
    "    def forward(self, x:  torch.Tensor, dim: int = 0, p: int = 1):\n",
    "        x = x * self.scale_rate\n",
    "        if self.normalizer:\n",
    "            x = self.normalizer(x, dim=dim, p=p)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scale_controller(name: str, kwargs=None) -> Union[ScaleControllerBase, None]:\n",
    "    \"\"\"\n",
    "    A tool function that help to select scale controller easily.\n",
    "    :param name: name of scale controller, choice now: 'learn', 'fix', 'relu', 'exp', 'softmax', 'norm'\n",
    "    :param kwargs: necessary controller parameter in dictionary style\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not name or name == 'none':\n",
    "        return None\n",
    "    controller_choices = {\n",
    "        'learn': LearnableScaleController,\n",
    "        'fix': FixedScaleController,\n",
    "        'relu': ReluScaleController,\n",
    "        'exp': ExpScaleController,\n",
    "        'softmax': SoftmaxScaleController,\n",
    "        'norm': NormalizeScaleController,\n",
    "    }\n",
    "    if name not in controller_choices:\n",
    "        raise KeyError('Wrong scale controller name.')\n",
    "    controller_type = controller_choices[name]\n",
    "    return controller_type(**kwargs) if kwargs else controller_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scaler_args(name : str, normalizer: ScaleControllerBase, scale_r: float = None):\n",
    "    ret = None\n",
    "    if name == 'learn':\n",
    "        ret = {'normalizer': normalizer}\n",
    "    elif name == 'fix':\n",
    "        ret = {'normalizer': normalizer, 'scale_rate': scale_r}\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 举例：\n",
    "\n",
    "class Config():\n",
    "    do_debug = False\n",
    "\n",
    "opt = Config()\n",
    "opt.emission_normalizer = None\n",
    "opt.emission_scaler = \"learn\"\n",
    "\n",
    "ems_normalizer = build_scale_controller(\n",
    "        name=opt.emission_normalizer\n",
    "    )\n",
    "ems_scaler = build_scale_controller(\n",
    "    name=opt.emission_scaler,\n",
    "    kwargs=make_scaler_args(opt.emission_scaler, ems_normalizer, opt.ems_scale_r)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity function\n",
    "\n",
    "相似度计算函数\n",
    "\n",
    "可选的有 'cosine', 'dot', 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reps_dot(sent1_reps: torch.Tensor, sent2_reps: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    calculate representation dot production\n",
    "    :param sent1_reps: (N, sent1_len, reps_dim)\n",
    "    :param sent2_reps: (N, sent2_len, reps_dim)\n",
    "    :return: (N, sent1_len, sent2_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 注意这里的 torch.bmm 的用法 (N, sent1_len, reps_dim ) * (N, reps_dim, sent2_len, )\n",
    "    return torch.bmm(sent1_reps, torch.transpose(sent2_reps, -1, -2))  # shape: (N, seq_len1, seq_len2)\n",
    "\n",
    "\n",
    "def reps_l2_sim(sent1_reps: torch.Tensor, sent2_reps: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    calculate representation L2 similarity\n",
    "    实际就是负的L2距离\n",
    "    \n",
    "    :param sent1_reps: (N, sent1_len, reps_dim)\n",
    "    :param sent2_reps: (N, sent2_len, reps_dim)\n",
    "    :return: (N, sent1_len, sent2_len)\n",
    "    \"\"\"\n",
    "    sent1_len = sent1_reps.shape[-2]\n",
    "    sent2_len = sent2_reps.shape[-2]\n",
    "    expand_shape1 = list(sent2_reps.shape)\n",
    "    expand_shape1.insert(2, sent2_len)\n",
    "    expand_shape2 = list(sent2_reps.shape)\n",
    "    expand_shape2.insert(1, sent1_len)\n",
    "\n",
    "    # shape: (N, seq_len1, seq_len2, emb_dim)\n",
    "    expand_reps1 = sent1_reps.unsqueeze(2).expand(expand_shape1)\n",
    "    expand_reps2 = sent2_reps.unsqueeze(1).expand(expand_shape2)\n",
    "\n",
    "    # shape: (N, seq_len1, seq_len2)\n",
    "    sim = torch.norm(expand_reps1 - expand_reps2, dim=-1, p=2)\n",
    "    return -sim  # we calculate similarity not distance here\n",
    "\n",
    "def reps_cosine_sim(sent1_reps: torch.Tensor, sent2_reps: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    calculate representation cosine similarity, note that this is different from torch version(that compute parwisely)\n",
    "    先求dot product，然后除以模长\n",
    "    \n",
    "    :param sent1_reps: (N, sent1_len, reps_dim)\n",
    "    :param sent2_reps: (N, sent2_len, reps_dim)\n",
    "    :return: (N, sent1_len, sent2_len)\n",
    "    \"\"\"\n",
    "    dot_sim = torch.bmm(sent1_reps, torch.transpose(sent2_reps, -1, -2))  # shape: (batch, seq_len1, seq_len2)\n",
    "    sent1_reps_norm = torch.norm(sent1_reps, dim=-1, keepdim=True)  # shape: (batch, seq_len1, 1)\n",
    "    sent2_reps_norm = torch.norm(sent2_reps, dim=-1, keepdim=True)  # shape: (batch, seq_len2, 1)\n",
    "    norm_product = torch.bmm(sent1_reps_norm,\n",
    "                             torch.transpose(sent2_reps_norm, -1, -2))  # shape: (batch, seq_len1, seq_len2)\n",
    "    sim_predicts = dot_sim / norm_product  # shape: (batch, seq_len1, seq_len2)\n",
    "    return sim_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.similarity = \"dot\"\n",
    "\n",
    "if opt.similarity == 'dot':\n",
    "    sim_func = reps_dot\n",
    "elif opt.similarity == 'cosine':\n",
    "    sim_func = reps_cosine_sim\n",
    "elif opt.similarity == 'l2':\n",
    "    sim_func = reps_l2_sim\n",
    "else:\n",
    "    raise TypeError('wrong component type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityScorerBase(torch.nn.Module):\n",
    "    def __init__(self, sim_func, emb_log=None):\n",
    "        super(SimilarityScorerBase, self).__init__()\n",
    "        self.sim_func = sim_func\n",
    "        self.emb_log = emb_log\n",
    "        self.log_content = ''\n",
    "        self.mlc_support_tags_mask = None\n",
    "\n",
    "    def update_mlc_support_tags_mask(self, support_targets, support_output_mask):\n",
    "        \"\"\"\n",
    "        update the mlc_support_tags_mask\n",
    "        :param support_targets: (batch_size, support_size, max_label_num, num_tags)\n",
    "        :param support_output_mask: (batch_size, support_size, max_label_num)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = support_targets.size(0)\n",
    "        num_tags = support_targets.size(-1)\n",
    "        \n",
    "        support_output_mask = support_output_mask.unsqueeze(-1).expand_as(support_targets)\n",
    "        \n",
    "        tags_mask = support_output_mask * support_targets  # (batch_size, support_size, max_label_num, num_tags)\n",
    "        tags_mask = torch.sum(tags_mask.contiguous().view(batch_size, -1, num_tags), dim=1)\n",
    "        tags_mask = (tags_mask >= 1).float()\n",
    "        self.mlc_support_tags_mask = tags_mask\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_reps: torch.Tensor,\n",
    "            support_reps: torch.Tensor,\n",
    "            test_output_mask: torch.Tensor,\n",
    "            support_output_mask: torch.Tensor,\n",
    "            support_targets: torch.Tensor = None,\n",
    "            label_reps: torch.Tensor = None, ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "            :param test_reps: (batch_size, support_size, test_seq_len, dim)\n",
    "            :param support_reps: (batch_size, support_size, support_seq_len)\n",
    "            :param test_output_mask: (batch_size, test_seq_len)\n",
    "            :param support_output_mask: (batch_size, support_size, support_seq_len)\n",
    "            :param support_targets: one-hot label targets: (batch_size, support_size, support_seq_len, num_tags)\n",
    "            :param label_reps: (batch_size, num_tags, dim)\n",
    "            :return: similarity\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def mask_sim(self, sim: torch.Tensor, mask1: torch.Tensor, mask2: torch.Tensor):\n",
    "        \"\"\"\n",
    "        去除掉无意义的similarity计算，比如对padding的： support  set 的多标签labels，是有padding的；\n",
    "        \n",
    "        mask invalid similarity to 0, i.e. sim to pad token is 0 here.\n",
    "        :param sim: similarity matrix (num sim, test_len, support_len)\n",
    "        :param mask1: (num sim, test_len, support_len)\n",
    "        :param mask2: (num sim, test_len, support_len)\n",
    "        :param min_value: the minimum value for similarity score\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mask1 = mask1.unsqueeze(-1).float()  # (b * s, test_label_num, 1)\n",
    "        mask2 = mask2.unsqueeze(-1).float()  # (b * s, support_label_num, 1)\n",
    "        mask = reps_dot(mask1, mask2)  # (b * s, test_label_num, support_label_num)\n",
    "        sim = sim * mask\n",
    "        return sim\n",
    "\n",
    "    def expand_it(self, item: torch.Tensor, support_size):\n",
    "        item = item.unsqueeze(1)\n",
    "        expand_shape = list(item.shape)\n",
    "        expand_shape[1] = support_size\n",
    "        return item.expand(expand_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoWithLabelSimilarityScorer(SimilarityScorerBase):\n",
    "    def __init__(self, sim_func, scaler=None, emb_log=None):\n",
    "        super(ProtoWithLabelSimilarityScorer, self).__init__(sim_func=sim_func, emb_log=emb_log)\n",
    "        self.scaler = scaler  # 浮点数，缩放\n",
    "        self.emb_log = emb_log\n",
    "        self.idx = 0\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_reps: torch.Tensor,\n",
    "            support_reps: torch.Tensor,\n",
    "            test_output_mask: torch.Tensor,\n",
    "            support_output_mask: torch.Tensor,\n",
    "            support_targets: torch.Tensor = None,\n",
    "            label_reps: torch.Tensor = None,) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "            calculate similarity between token and each label's prototype.\n",
    "            :param test_reps: (batch_size, support_size, test_seq_len, dim)\n",
    "            :param support_reps: (batch_size, support_size, support_seq_len)\n",
    "            :param test_output_mask: (batch_size, test_seq_len)\n",
    "            :param support_output_mask: (batch_size, support_size, support_seq_len)   # 帮助区分哪个部分是padding\n",
    "            :param support_targets: one-hot label targets: (batch_size, support_size, support_seq_len, num_tags) 进行了one-hot编码的多标签\n",
    "            :param label_reps: (batch_size, num_tags, dim)\n",
    "            :return: similarity: (batch_size, test_seq_len, num_tags)\n",
    "        \"\"\"\n",
    "        '''get data attribute'''\n",
    "        support_size = support_reps.shape[1]\n",
    "        test_len = test_reps.shape[-2]  # non-word-piece max test token num, Notice that it's different to input t len\n",
    "        support_len = support_reps.shape[-2]  # non-word-piece max test token num\n",
    "        emb_dim = test_reps.shape[-1]\n",
    "        batch_size = test_reps.shape[0]\n",
    "        num_tags = support_targets.shape[-1]\n",
    "        \n",
    "        # 计算prototype向量： onehot向量support_targets 与 support_reps相乘，然后取平均\n",
    "        '''get prototype reps'''\n",
    "        # flatten dim mention of support size and batch size.\n",
    "        # shape (batch_size * support_size, sent_len, emb_dim)\n",
    "        support_reps = support_reps.view(-1, support_len, emb_dim)\n",
    "\n",
    "        # shape (batch_size * support_size, sent_len, num_tags)\n",
    "        # print(\"Debug\", test_reps.shape, support_targets.shape)\n",
    "        support_targets = support_targets.view(batch_size * support_size, support_len, num_tags).float()\n",
    "\n",
    "        # shape (batch_size, support_size, num_tags, emd_dim)\n",
    "        sum_reps = torch.bmm(torch.transpose(support_targets, -1, -2), support_reps)\n",
    "        # sum up tag emb over support set, shape (batch_size, num_tags, emd_dim)\n",
    "        sum_reps = torch.sum(sum_reps.view(batch_size, support_size, num_tags, emb_dim), dim=1)\n",
    "\n",
    "        # get num of each tag in support set, shape: (batch_size, num_tags, 1)\n",
    "        tag_count = torch.sum(support_targets.view(batch_size, -1, num_tags), dim=1).unsqueeze(-1)\n",
    "        # divide by 0 occurs when the tags, such as \"I-x\", are not existing in support.\n",
    "        tag_count = self.remove_0(tag_count)\n",
    "        prototype_reps = torch.div(sum_reps, tag_count)  # shape (batch_size, num_tags, emd_dim)\n",
    "        \n",
    "        ################\n",
    "        # 提问\n",
    "        ################\n",
    "        ''' 为什么这里的 prototype_reps 还与 batch_size 相关？每个batch里面的support set都是相同的，为什么还要再维持这个更大的tensor？  '''\n",
    "        # query 和 support set； \n",
    "        \n",
    "        # add PAD label\n",
    "        if label_reps is not None:\n",
    "            # 添加PAD的向量表征\n",
    "            label_reps = torch.cat((torch.zeros_like(label_reps).narrow(dim=-2, start=0, length=1), label_reps), dim=-2)\n",
    "            \n",
    "            # 这里就是论文中的anchored label representation： label name的表征 与 prototype的加权平均\n",
    "            prototype_reps = (1 - self.scaler) * prototype_reps + self.scaler * label_reps\n",
    "\n",
    "        '''get final test data reps'''\n",
    "        # average test representation over support set (reps for each support sent can be different)\n",
    "        # 之前，query与每个support 样本拼接，得到了不同的表征\n",
    "        test_reps = torch.mean(test_reps, dim=1)  # shape (batch_size, sent_len, emb_dim)\n",
    "        \n",
    "        # 计算相似度\n",
    "        '''calculate dot product'''\n",
    "        sim_score = self.sim_func(test_reps, prototype_reps)  # shape (batch_size, sent_len, num_tags)\n",
    "\n",
    "        '''store visualization embedding'''\n",
    "        if not self.training and self.emb_log:\n",
    "            log_context = '\\n'.join(\n",
    "                ['test_' + str(self.idx) + '-' + str(idx) + '-' + str(idx2) + '\\t' + '\\t'.join(map(str, item2))\n",
    "                 for idx, item in enumerate(test_reps.tolist()) for idx2, item2 in enumerate(item)]) + '\\n'\n",
    "            log_context += '\\n'.join(\n",
    "                ['proto_' + str(self.idx) + '-' + str(idx) + '-' + str(idx2) + '\\t' + '\\t'.join(map(str, item2))\n",
    "                 for idx, item in enumerate(prototype_reps.tolist()) for idx2, item2 in enumerate(item)]) + '\\n'\n",
    "            self.idx += batch_size\n",
    "            self.emb_log.write(log_context)\n",
    "\n",
    "        return sim_score\n",
    "\n",
    "    def remove_nan(self, my_tensor):\n",
    "        \"\"\"\n",
    "        Using 'torch.where' here because:\n",
    "        modifying tensors in-place can cause issues with backprop.\n",
    "        \"\"\"\n",
    "        return torch.where(torch.isnan(my_tensor), torch.zeros_like(my_tensor), my_tensor)\n",
    "\n",
    "    def remove_0(self, my_tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        return my_tensor + 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### emission\n",
    "\n",
    "相似度计算 + 相似度分数调整的方法；\n",
    "\n",
    "支持：'mnet', 'rank', 'proto', 'proto_with_label', 'tapnet'\n",
    "\n",
    "主要关注： proto_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmissionScorerBase(torch.nn.Module):\n",
    "    def __init__(self, similarity_scorer: SimilarityScorerBase, scaler: ScaleControllerBase = None):\n",
    "        \"\"\"\n",
    "        :param similarity_scorer: Module for calculating token similarity\n",
    "        \"\"\"\n",
    "        super(EmissionScorerBase, self).__init__()\n",
    "        self.similarity_scorer = similarity_scorer\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_reps: torch.Tensor,\n",
    "            support_reps: torch.Tensor,\n",
    "            test_output_mask: torch.Tensor,\n",
    "            support_output_mask: torch.Tensor,\n",
    "            support_targets: torch.Tensor,\n",
    "            label_reps: torch.Tensor = None, ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param test_reps: (batch_size, support_size, test_seq_len, dim), notice: reps has been expand to support size\n",
    "        :param support_reps: (batch_size, support_size, support_seq_len)\n",
    "        :param test_output_mask: (batch_size, test_seq_len)\n",
    "        :param support_output_mask: (batch_size, support_size, support_seq_len)\n",
    "        :param support_targets: one-hot label targets: (batch_size, support_size, support_seq_len, num_tags)\n",
    "        :param label_reps: (batch_size, num_tags, dim)\n",
    "        :return: emission, shape: (batch_size, test_len, no_pad_num_tags)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其实就是前面的SimilarityScorer与scaler的结合\n",
    "\n",
    "class ProtoWithLabelEmissionScorer(EmissionScorerBase):\n",
    "    def __init__(self, similarity_scorer: ProtoWithLabelSimilarityScorer, scaler: ScaleControllerBase = None):\n",
    "        \"\"\"\n",
    "        :param similarity_scorer: Module for calculating token similarity\n",
    "        \"\"\"\n",
    "        super(ProtoWithLabelEmissionScorer, self).__init__(similarity_scorer, scaler)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            test_reps: torch.Tensor,\n",
    "            support_reps: torch.Tensor,\n",
    "            test_output_mask: torch.Tensor,\n",
    "            support_output_mask: torch.Tensor,\n",
    "            support_targets: torch.Tensor,\n",
    "            label_reps: torch.Tensor = None, ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param test_reps: (batch_size, support_size, test_seq_len, dim), notice: reps has been expand to support size\n",
    "        :param support_reps: (batch_size, support_size, support_seq_len)\n",
    "        :param test_output_mask: (batch_size, test_seq_len)\n",
    "        :param support_output_mask: (batch_size, support_size, support_seq_len)\n",
    "        :param support_targets: one-hot label targets: (batch_size, support_size, support_seq_len, num_tags)\n",
    "        :param label_reps: (batch_size, num_tags, dim)\n",
    "        :return: emission, shape: (batch_size, test_len, no_pad_num_tags)\n",
    "        \"\"\"\n",
    "        similarity = self.similarity_scorer(\n",
    "            test_reps, support_reps, test_output_mask, support_output_mask, support_targets, label_reps)\n",
    "        emission = self.get_emission(similarity, support_targets)  # shape(batch_size, test_len, no_pad_num_tag)\n",
    "        return emission\n",
    "\n",
    "    def get_emission(self, similarities: torch.Tensor, support_targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param similarities: (batch_size, support_size, test_seq_len, support_seq_len)\n",
    "        :param support_targets: one-hot label targets: (batch_size, support_size, support_seq_len, num_tags)\n",
    "        :return: emission: shape: (batch_size, test_len, no_pad_num_tags)\n",
    "        \"\"\"\n",
    "        batch_size, test_len, num_tags = similarities.shape\n",
    "        no_pad_num_tags = num_tags - 1  # block emission on pad\n",
    "        \n",
    "        #先去除PAD的分数\n",
    "        ''' cut emission to block predictions on [PAD] label (we use 0 as [PAD] label id) '''\n",
    "        emission = similarities.narrow(-1, 1, no_pad_num_tags)\n",
    "        \n",
    "        if self.scaler:\n",
    "            emission = self.scaler(emission, p=3, dim=-1)\n",
    "        return emission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "多标签的解码器\n",
    "\n",
    "支持： 'mlc', 'eamlc', 'msmlc', 'krnmsmlc'；\n",
    "\n",
    "主要关注： krnmsmlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelTextClassifier(torch.nn.Module):\n",
    "    def __init__(self, threshold=0.6, grad_threshold=True):\n",
    "        super(MultiLabelTextClassifier, self).__init__()\n",
    "        \n",
    "        # threshold作为模型的参数，可以进行参数更新(如果requires_grad=True)\n",
    "        self.threshold = nn.Parameter(torch.FloatTensor([threshold]), requires_grad=grad_threshold)\n",
    "        \n",
    "        # 多分类损失函数计算\n",
    "        self.criterion = nn.MultiLabelSoftMarginLoss()\n",
    "        self.right_estimate = None\n",
    "\n",
    "    def forward(self,\n",
    "                logits: torch.Tensor,\n",
    "                mask: torch.Tensor,\n",
    "                tags: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :param mask: (batch_size, 1)\n",
    "        :param tags: (batch_size, max_label_num), eg [[2, 15], [2, 0]]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self._compute_loss(logits, mask, tags)\n",
    "\n",
    "    def _compute_loss(self,\n",
    "                      logits: torch.Tensor,\n",
    "                      mask: torch.Tensor,\n",
    "                      targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :param mask: (batch_size, 1)\n",
    "        :param targets: (batch_size, max_label_num), eg [[2, 15], [2, 0]]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = mask.shape\n",
    "        # todo: test different normalization effectiveness.\n",
    "        # todo: check pad label\n",
    "\n",
    "        threshold = self.get_threshold(logits)\n",
    "        # Normalization has been done in emission's scaler\n",
    "        filtered_logits = logits - threshold  # For each pos, > 0 for positive tag, < 0 for negative tag\n",
    "        \n",
    "        # 形状 (N, C)\n",
    "        multi_hot_target = self.create_multi_hot(targets, label_num=logits.shape[-1])\n",
    "\n",
    "        loss = self.criterion(filtered_logits, multi_hot_target)\n",
    "        return loss\n",
    "\n",
    "    def create_multi_hot(self, y: torch.Tensor, label_num: int):\n",
    "        \"\"\"\n",
    "        :param y:  (batch_size, max_label_num), eg [[2, 15], [2, 0]]\n",
    "        :param label_num: num of\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = y.shape[0]\n",
    "        y_one_hot = torch.zeros(batch_size, label_num).to(y.device)\n",
    "        return y_one_hot.scatter(1, y, 1)\n",
    "\n",
    "    def decode(self, logits: torch.Tensor) -> List[List[int]]:\n",
    "        \"\"\" collect the values greater than threshold. \"\"\"\n",
    "        # shape: (batch_size, 1, no_pad_num_tag) -> (batch_size, 1, no_pad_num_tag)\n",
    "        threshold = self.get_threshold(logits)\n",
    "        preds = (logits - threshold).squeeze()\n",
    "        ret = []\n",
    "        for pred in preds:\n",
    "            temp = []\n",
    "            for l_id, score in enumerate(pred):\n",
    "                if bool(score > 0):\n",
    "                    temp.append(int(l_id))\n",
    "            # predict the label with most probability\n",
    "            \n",
    "            # 如果没有预测是概率大于阈值的，则取最大概率的那一个 \n",
    "            if not temp:\n",
    "                temp = [int(torch.argmax(pred))]\n",
    "            ret.append(temp)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_threshold(self, logits):\n",
    "        return self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入论文中的 logits adaptive机制\n",
    "\n",
    "class EAMultiLabelTextClassifier(MultiLabelTextClassifier):\n",
    "    \"\"\" Emission adaptive MultiLabelTextClassifier\n",
    "        (1) Adaptive threshold λ is calculated by observing emission scores as:\n",
    "        λ =（E_max−E_min ）× r + E_min\n",
    "        where E is emission, r is emission rate.\n",
    "\n",
    "        (2) Then different sample has different threshold for different logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.6, grad_threshold=True):\n",
    "        \"\"\"\n",
    "        Here self.threshold is used as emission rate.\n",
    "        \"\"\"\n",
    "        super(EAMultiLabelTextClassifier, self).__init__(threshold, grad_threshold)\n",
    "\n",
    "    def get_threshold(self, logits):\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :return: (batch_size, 1, 1)\n",
    "        \"\"\"\n",
    "        # 根据公式计算动态自适应的阈值\n",
    "        # 思考： 本文的场景是：我知道每个样本都至少有标签；如果不是这样的，那我应该如何做出改变？\n",
    "        \n",
    "        # 这里的 self.threshold 参数含义就变了：权重\n",
    "        max_logits = torch.max(logits, dim=-1)[0]  # fetch value, give up indexes.\n",
    "        min_logits = torch.min(logits, dim=-1)[0]\n",
    "        threshold = (max_logits - min_logits) * self.threshold + min_logits  # (batch_size, 1)\n",
    "        return threshold.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaStatsMultiLabelTextClassifier(EAMultiLabelTextClassifier):\n",
    "    \"\"\" Meta statistic MultiLabelTextClassifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.6, grad_threshold=True, meta_rate=0.5, ab_ea=False):\n",
    "        super(MetaStatsMultiLabelTextClassifier, self).__init__(threshold, grad_threshold)\n",
    "        self.num_stats = None\n",
    "        self.meta_rate = meta_rate   # \n",
    "        self.ab_ea = ab_ea\n",
    "\n",
    "    def update_statistics(self, support_targets):\n",
    "        \"\"\"\n",
    "        Update stats for each sample in batch.\n",
    "        :param support_targets: one-hot targets (batch_size, support_size, max_label_num, num_tags)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # count label num\n",
    "        batch_size, support_size, max_label_num, num_tags = support_targets.shape\n",
    "        c_sup_targets = support_targets.narrow(dim=-1, start=1, length=num_tags-1) # 去除PAD\n",
    "        \n",
    "        # one-hot转为multi-hot\n",
    "        multi_hot_tgt = torch.sum(c_sup_targets, dim=-2)  # shape (batch_size, support_size, num_tags)\n",
    "        \n",
    "        label_num = torch.sum(multi_hot_tgt, dim=-1)  # shape (batch_size, support_size)\n",
    "        \n",
    "        # get stats for each sample in batch\n",
    "        label_num = [[it for it in item.tolist() if it] for item in label_num]  # del [PAD] label data\n",
    "        \n",
    "        # 得到每个样本有多少个label\n",
    "        self.num_stats = [Counter(n) for n in label_num]\n",
    "\n",
    "    def get_threshold(self, logits):\n",
    "        \"\"\"\n",
    "        Step1: Estimate threshold λ′ by observing support set:\n",
    "                λ′= ∑_N^i[p(k=i) E_(i+1)]\n",
    "        ,where N is label num, E_j is j_th largest ranked emission scores， p(k=i) 是经验count\n",
    "\n",
    "        Step2: Calibrate λ′ with meta parameter\n",
    "\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :return: (batch_size, 1, 1)\n",
    "        \"\"\"\n",
    "        ''' Estimate threshold '''\n",
    "        # get estimate thresholds: shape (batch_size)\n",
    "        estimate_thresholds = self.estimate_threshold(logits)\n",
    "        ''' Calibrate threshold '''\n",
    "        thresholds = self.calibrate_threshold(logits, estimate_thresholds)\n",
    "        return thresholds\n",
    "\n",
    "    def estimate_threshold(self, logits) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :return: shape (batch_size)\n",
    "        \"\"\"\n",
    "        # todo: check support set pad influence of\n",
    "        \n",
    "        # 根据经验分布来预估阈值\n",
    "        ret = []\n",
    "        for ind, logit in enumerate(logits):\n",
    "            # logits 排序\n",
    "            sorted_logits = sorted(logit[0], reverse=True)\n",
    "            \n",
    "            stats = self.num_stats[ind]\n",
    "            stats: Counter\n",
    "            \n",
    "            l_sum = 0\n",
    "            for num, count in stats.items():\n",
    "                l_sum += sorted_logits[int(num)] * count  # num is already rank + 1\n",
    "            ret.append(l_sum / len(list(stats.elements())))\n",
    "        ret = torch.stack(ret).to(logits.device)\n",
    "        return ret\n",
    "\n",
    "    def calibrate_threshold(self, logits, thresholds) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "\n",
    "        :param logits:\n",
    "        :param thresholds:\n",
    "        :return: (batch_size, 1, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.ab_ea: # 针对 emission adapting的\n",
    "            meta_threshold = self.threshold  # ablation EA threshold here\n",
    "        else:\n",
    "            meta_threshold = super().get_threshold(logits)  # use EA threshold here\n",
    "        \n",
    "        est_threshold = thresholds.unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        return est_threshold * (1 - self.meta_rate) + self.meta_rate * meta_threshold\n",
    "\n",
    "    def get_ea_threshold(self, logits):\n",
    "        return super().get_threshold(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaussian_kernel(input1, input2, bandwidth):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input1: (batch_size, support_size, feature_len)\n",
    "    :param input2: (batch_size, support_size, feature_len)\n",
    "    :param bandwidth:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 高斯核： 预测样本与其他已知样本进行对比； \n",
    "    input_x = (input1 - input2) / bandwidth\n",
    "    input_x = input_x.unsqueeze(-2)\n",
    "    \n",
    "    # 基于gauss核的权重\n",
    "    k_value = 1.0 / np.sqrt(np.pi) * torch.exp(-torch.matmul(input_x, input_x.permute(0, 1, 3, 2)) / 2)\n",
    "    k_value = k_value.squeeze(-1).squeeze(-1)\n",
    "    \n",
    "    return k_value\n",
    "\n",
    "\n",
    "class GaussianKernelSimilarityScorer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, bandwidth=0.5, learnable=False, map_dict=None):\n",
    "        super(GaussianKernelSimilarityScorer, self).__init__()\n",
    "        self.bandwidth = torch.nn.Parameter(torch.Tensor([bandwidth]), requires_grad=learnable)\n",
    "        self.map_dict = map_dict\n",
    "        self.feature_map = map_dict['feature_map']\n",
    "        self.feature_num = map_dict['feature_num']\n",
    "        self.feature_map_dim = map_dict['feature_map_dim']\n",
    "        self.feature_map_act = map_dict['feature_map_act']\n",
    "        self.feature_map_layer_num = map_dict['feature_map_layer_num']\n",
    "        \n",
    "        if self.feature_map:\n",
    "            modules = []\n",
    "            if self.feature_map_act == 'none':\n",
    "                modules.append(torch.nn.Linear(self.feature_num, self.feature_map_dim))\n",
    "                for _ in range(self.feature_map_layer_num - 1):\n",
    "                    modules.append(torch.nn.Linear(self.feature_map_dim, self.feature_map_dim))\n",
    "            elif self.feature_map_act == 'relu':\n",
    "                modules.append(torch.nn.Linear(self.feature_num, self.feature_map_dim))\n",
    "                modules.append(torch.nn.ReLU())\n",
    "                for _ in range(self.feature_map_layer_num - 1):\n",
    "                    modules.append(torch.nn.Linear(self.feature_map_dim, self.feature_map_dim))\n",
    "                    modules.append(torch.nn.ReLU())\n",
    "            elif self.feature_map_act == 'sigmoid':\n",
    "                modules.append(torch.nn.Linear(self.feature_num, self.feature_map_dim))\n",
    "                modules.append(torch.nn.Sigmoid())\n",
    "                for _ in range(self.feature_map_layer_num - 1):\n",
    "                    modules.append(torch.nn.Linear(self.feature_map_dim, self.feature_map_dim))\n",
    "                    modules.append(torch.nn.Sigmoid())\n",
    "            elif self.feature_map_act == 'tanh':\n",
    "                modules.append(torch.nn.Linear(self.feature_num, self.feature_map_dim))\n",
    "                modules.append(torch.nn.Tanh())\n",
    "                for _ in range(self.feature_map_layer_num - 1):\n",
    "                    modules.append(torch.nn.Linear(self.feature_map_dim, self.feature_map_dim))\n",
    "                    modules.append(torch.nn.Tanh())\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            self.map_linear = torch.nn.Sequential(*modules)\n",
    "            self.map_linear.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "        if type(w) == torch.nn.Linear:\n",
    "            torch.nn.init.xavier_normal_(w.weight)\n",
    "\n",
    "    def feature_norm(self, support_features, test_feature):\n",
    "        \"\"\"\n",
    "        :param support_features:  (batch_size, support_size, feature_len)\n",
    "        :param test_feature: (batch_size, feature_len)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.feature_map:\n",
    "            support_features = self.map_linear(support_features)\n",
    "            test_feature = self.map_linear(test_feature)\n",
    "\n",
    "        s_max = torch.max(support_features, dim=-2)[0]  # (batch_size, feature_len)\n",
    "        s_min = torch.min(support_features, dim=-2)[0]  # (batch_size, feature_len)\n",
    "\n",
    "        s_max = torch.max(s_max, test_feature)  # (batch_size, feature_len)\n",
    "        s_min = torch.min(s_min, test_feature)  # (batch_size, feature_len)\n",
    "\n",
    "        scale = s_max - s_min  # (batch_size, feature_len)\n",
    "        # if scale equal to 0, then add 1\n",
    "        scale = scale + (scale == 0).float()\n",
    "\n",
    "        s_features = (support_features - s_min.unsqueeze(-2).expand_as(support_features))\n",
    "        s_features = s_features / scale.unsqueeze(-2).expand_as(support_features)\n",
    "\n",
    "        t_feature = (test_feature - s_min) / scale\n",
    "\n",
    "        return s_features, t_feature\n",
    "\n",
    "    def forward(self,\n",
    "                support_sentence_feature: torch.Tensor,\n",
    "                test_sentence_feature: torch.Tensor,\n",
    "                support_sentence_target: torch.Tensor,\n",
    "                test_sentence_target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        :param support_sentence_feature:  (batch_size, support_size, feature_len)\n",
    "        :param test_sentence_feature:  (batch_size, feature_len)\n",
    "        :param support_sentence_target:  (batch_size, support_size)\n",
    "        :param test_sentence_target:  (batch_size, 1)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        # 将特征数值进行 最大值-最小值 标准化\n",
    "        support_sentence_feature, test_sentence_feature = \\\n",
    "            self.feature_norm(support_sentence_feature, test_sentence_feature)\n",
    "        \n",
    "        # 基于高斯核计算出权重\n",
    "        test_sentence_feature = test_sentence_feature.unsqueeze(1).expand_as(support_sentence_feature)\n",
    "        self.bandwidth.to(support_sentence_feature.device)\n",
    "        k_values = gaussian_kernel(test_sentence_feature, support_sentence_feature, self.bandwidth)\n",
    "\n",
    "        k_values_sum = torch.sum(k_values, dim=-1, keepdim=True)\n",
    "        k_values_sum = k_values_sum.expand_as(k_values)\n",
    "        k_weights = k_values / k_values_sum  # (batch_size, support_size)\n",
    "\n",
    "        return k_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRNMetaStatsMultiLabelTextClassifier(MetaStatsMultiLabelTextClassifier):\n",
    "\n",
    "    def __init__(self, threshold=0.6, grad_threshold=True,\n",
    "                 meta_rate=0.5, ab_ea=False,\n",
    "                 kernel='gaussian', bandwidth=0.5,\n",
    "                 use_gold=False, learnable=False,\n",
    "                 map_dict=None):\n",
    "        super(KRNMetaStatsMultiLabelTextClassifier, self).__init__(threshold, grad_threshold, meta_rate, ab_ea)\n",
    "        self.kernel = kernel\n",
    "        self.bandwidth = bandwidth\n",
    "        self.learnable = learnable\n",
    "        self.use_gold = use_gold\n",
    "        self.map_dict = map_dict\n",
    "        self.similarity_scorer = self.choose_kernel_similar()\n",
    "        if self.learnable:\n",
    "            self.label_num_criterion = nn.MSELoss()\n",
    "            self.label_num_loss = None\n",
    "\n",
    "    def choose_kernel_similar(self):\n",
    "        if self.kernel == 'gaussian':\n",
    "            similarity_scorer = GaussianKernelSimilarityScorer(bandwidth=self.bandwidth, learnable=self.learnable,\n",
    "                                                               map_dict=self.map_dict)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return similarity_scorer\n",
    "\n",
    "    def update_statistics(self,\n",
    "                          support_targets,\n",
    "                          support_sentence_feature=None,\n",
    "                          test_sentence_feature=None,\n",
    "                          support_sentence_label_num=None,\n",
    "                          test_sentence_label_num=None):\n",
    "        \"\"\"\n",
    "        Update stats for each sample in batch.\n",
    "        :param support_targets: one-hot targets (batch_size, support_size, max_label_num, num_tags)\n",
    "        :param support_sentence_feature: (batch_size, support_size, feature_len)\n",
    "        :param test_sentence_feature: (batch_size, feature_len)\n",
    "        :param support_sentence_label_num: (batch_size, support_size)\n",
    "        :param test_sentence_label_num: (batch_size)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        ''' count label num '''\n",
    "        # 设置为 use_gold = False\n",
    "        if self.use_gold:\n",
    "            t_target = test_sentence_label_num.squeeze(-1)\n",
    "            self.num_stats = [{item: [1]} for item in t_target.long().tolist()]\n",
    "            self.right_estimate = (t_target == t_target).long()\n",
    "        else:\n",
    "            \n",
    "            # 根据高斯核得到权重\n",
    "            label_num_weights = self.similarity_scorer(support_sentence_feature, test_sentence_feature,\n",
    "                                                       support_sentence_label_num, test_sentence_label_num)\n",
    "\n",
    "            # get the distributed num stats\n",
    "            batch_size = label_num_weights.size(0)\n",
    "            self.num_stats = []\n",
    "            for b_idx in range(batch_size):\n",
    "                tmp_stat = {}\n",
    "                for s_label_num, weight in zip(support_sentence_label_num[b_idx].long().tolist(),\n",
    "                                               label_num_weights[b_idx].tolist()):\n",
    "                    if s_label_num not in tmp_stat:\n",
    "                        tmp_stat[s_label_num] = [weight]\n",
    "                    else:\n",
    "                        tmp_stat[s_label_num].append(weight)\n",
    "                self.num_stats.append(tmp_stat)\n",
    "            \n",
    "            # 看kernel regression是不是正确的\n",
    "            # calculate the label num accuracy\n",
    "            pred_label_num = torch.sum(label_num_weights * support_sentence_label_num, dim=-1)\n",
    "            pred_label_num_int = torch.round(pred_label_num)\n",
    "            \n",
    "            self.right_estimate = (pred_label_num_int == test_sentence_label_num.squeeze(-1)).long()\n",
    "            \n",
    "            # 实际使用的模型 设置  learnable = True\n",
    "            if self.learnable:\n",
    "                self.label_num_loss = self.label_num_criterion(pred_label_num, test_sentence_label_num.squeeze(-1))\n",
    "\n",
    "    def estimate_threshold(self, logits) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :return: shape (batch_size)\n",
    "        \"\"\"\n",
    "        # todo: check support set pad influence of\n",
    "        ret = []\n",
    "        for ind, logit in enumerate(logits):\n",
    "            sorted_logits = sorted(logit[0], reverse=True)\n",
    "            stats = self.num_stats[ind]\n",
    "            stats: Dict\n",
    "            l_sum = 0\n",
    "            for num, count_lst in stats.items():\n",
    "                l_sum += sorted_logits[int(num)] * sum(count_lst)\n",
    "            ret.append(l_sum)\n",
    "        ret = torch.stack(ret).to(logits.device)\n",
    "        return ret\n",
    "\n",
    "    def _compute_loss(self,\n",
    "                      logits: torch.Tensor,\n",
    "                      mask: torch.Tensor,\n",
    "                      targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param logits: (batch_size, 1, n_tags)\n",
    "        :param mask: (batch_size, 1)\n",
    "        :param targets: (batch_size, max_label_num), eg [[2, 15], [2, 0]]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 标签预测的损失 + label num 预测的损失\n",
    "        loss = super()._compute_loss(logits, mask, targets)\n",
    "        if self.learnable:\n",
    "            loss += self.label_num_loss\n",
    "        return loss\n",
    "\n",
    "    def decode(self, logits: torch.Tensor, test_label_num=None) -> List[List[int]]:\n",
    "        \"\"\" collect the values greater than threshold. \"\"\"\n",
    "        # shape: (batch_size, 1, no_pad_num_tag) -> (batch_size, 1, no_pad_num_tag)\n",
    "        \n",
    "        # 这部分的写法与之前是一致的\n",
    "        if self.use_gold:\n",
    "            test_label_num = test_label_num.squeeze(-1).long().tolist()  # (batch_size, )\n",
    "            ret = []\n",
    "            for label_num, logit in zip(test_label_num, logits):\n",
    "                sorted_logits = sorted(logit[0], reverse=True)\n",
    "                threshold_logit = sorted_logits[label_num]\n",
    "                threshold_logit = threshold_logit.unsqueeze(-1).expand_as(logit)\n",
    "                pred = (logit - threshold_logit).squeeze()  # (batch_size, )\n",
    "                temp = []\n",
    "                for l_id, score in enumerate(pred):\n",
    "                    if bool(score >= 0):\n",
    "                        temp.append(int(l_id))\n",
    "                # predict the label with most probability\n",
    "                if not temp:\n",
    "                    temp = [int(torch.argmax(pred))]\n",
    "                ret.append(temp)\n",
    "        else:\n",
    "            ret = super().decode(logits)\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型汇总\n",
    "\n",
    "将模型的各个模块串起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(opt, config):\n",
    "    \"\"\" Customize and build the few-shot learning model from components \"\"\"\n",
    "\n",
    "    ''' Build context_embedder '''\n",
    "    if opt.context_emb == 'bert':\n",
    "        context_embedder = BertSchemaContextEmbedder(opt=opt) if opt.use_schema else BertContextEmbedder(opt=opt)\n",
    "    elif opt.context_emb == 'sep_bert':\n",
    "        context_embedder = BertSchemaSeparateContextEmbedder(opt=opt) if opt.use_schema else \\\n",
    "            BertSeparateContextEmbedder(opt=opt)\n",
    "    elif opt.context_emb == 'electra':\n",
    "        context_embedder = ElectraSchemaContextEmbedder(opt=opt) if opt.use_schema else ElectraContextEmbedder(opt=opt)\n",
    "    elif opt.context_emb == 'elmo':\n",
    "        raise NotImplementedError\n",
    "    elif opt.context_emb == 'raw':\n",
    "        context_embedder = NormalContextEmbedder(opt=opt, num_token=len(opt.word2id))\n",
    "    else:\n",
    "        raise TypeError('wrong component type')\n",
    "\n",
    "    ''' Create log file to record testing data '''\n",
    "    if opt.emb_log:\n",
    "        emb_log = open(os.path.join(opt.output_dir, 'emb.log'), 'w')\n",
    "        if 'id2label' in config:\n",
    "            emb_log.write('id2label\\t' + '\\t'.join([str(k) + ':' + str(v) for k, v in config['id2label'].items()]) + '\\n')\n",
    "    else:\n",
    "        emb_log = None\n",
    "\n",
    "    '''Build emission scorer and similarity scorer '''\n",
    "    # build scaler\n",
    "    ems_normalizer = build_scale_controller(\n",
    "        name=opt.emission_normalizer\n",
    "    )\n",
    "    ems_scaler = build_scale_controller(\n",
    "        name=opt.emission_scaler,\n",
    "        kwargs=make_scaler_args(opt.emission_scaler, ems_normalizer, opt.ems_scale_r)\n",
    "    )\n",
    "    if opt.similarity == 'dot':\n",
    "        sim_func = reps_dot\n",
    "    elif opt.similarity == 'cosine':\n",
    "        sim_func = reps_cosine_sim\n",
    "    elif opt.similarity == 'l2':\n",
    "        sim_func = reps_l2_sim\n",
    "    else:\n",
    "        raise TypeError('wrong component type')\n",
    "\n",
    "    if opt.emission == 'mnet':\n",
    "        similarity_scorer = MatchingSimilarityScorer(sim_func=sim_func, emb_log=emb_log)\n",
    "        emission_scorer = MNetEmissionScorer(similarity_scorer, ems_scaler, opt.div_by_tag_num)\n",
    "    elif opt.emission == 'proto':\n",
    "        similarity_scorer = PrototypeSimilarityScorer(sim_func=sim_func, emb_log=emb_log)\n",
    "        emission_scorer = PrototypeEmissionScorer(similarity_scorer, ems_scaler)\n",
    "    elif opt.emission == 'proto_with_label':\n",
    "        similarity_scorer = ProtoWithLabelSimilarityScorer(sim_func=sim_func, scaler=opt.ple_scale_r, emb_log=emb_log)\n",
    "        emission_scorer = ProtoWithLabelEmissionScorer(similarity_scorer, ems_scaler)\n",
    "    elif opt.emission == 'tapnet':\n",
    "        # set num of anchors:\n",
    "        # (1) if provided in config, use it (usually in load model case.)\n",
    "        # (2) *3 is used to ensure enough anchors ( > num_tags of unseen domains )\n",
    "        num_anchors = config['num_anchors'] if 'num_anchors' in config else config['num_tags'] * 3\n",
    "        config['num_anchors'] = num_anchors\n",
    "        anchor_dim = 256 if opt.context_emb == 'electra' else 768\n",
    "        similarity_scorer = TapNetSimilarityScorer(\n",
    "            sim_func=sim_func, num_anchors=num_anchors, mlp_out_dim=opt.tap_mlp_out_dim,\n",
    "            random_init=opt.tap_random_init, random_init_r=opt.tap_random_init_r,\n",
    "            mlp=opt.tap_mlp, emb_log=emb_log, tap_proto=opt.tap_proto, tap_proto_r=opt.tap_proto_r,\n",
    "            anchor_dim=anchor_dim)\n",
    "        emission_scorer = TapNetEmissionScorer(similarity_scorer, ems_scaler)\n",
    "    else:\n",
    "        raise TypeError('wrong component type')\n",
    "\n",
    "    ''' Build decoder '''\n",
    "    if opt.task == 'sl': # for sequence labeling\n",
    "        if opt.decoder == 'sms':\n",
    "            transition_scorer = None\n",
    "            decoder = SequenceLabeler()\n",
    "        elif opt.decoder == 'rule':\n",
    "            transition_scorer = None\n",
    "            decoder = RuleSequenceLabeler(config['id2label'])\n",
    "        elif opt.decoder == 'crf':\n",
    "            # Notice: only train back-off now\n",
    "            trans_normalizer = build_scale_controller(name=opt.trans_normalizer)\n",
    "            trans_scaler = build_scale_controller(\n",
    "                name=opt.trans_scaler, kwargs=make_scaler_args(opt.trans_scaler, trans_normalizer, opt.trans_scale_r))\n",
    "            if opt.transition == 'learn':\n",
    "                transition_scorer = FewShotTransitionScorer(\n",
    "                    num_tags=config['num_tags'], normalizer=trans_normalizer, scaler=trans_scaler,\n",
    "                    r=opt.trans_r, backoff_init=opt.backoff_init)\n",
    "            elif opt.transition == 'learn_with_label':\n",
    "                label_trans_normalizer = build_scale_controller(name=opt.label_trans_normalizer)\n",
    "                label_trans_scaler = build_scale_controller(name=opt.label_trans_scaler, kwargs=make_scaler_args(\n",
    "                        opt.label_trans_scaler, label_trans_normalizer, opt.label_trans_scale_r))\n",
    "                transition_scorer = FewShotTransitionScorerFromLabel(\n",
    "                    num_tags=config['num_tags'], normalizer=trans_normalizer, scaler=trans_scaler,\n",
    "                    r=opt.trans_r, backoff_init=opt.backoff_init, label_scaler=label_trans_scaler)\n",
    "            else:\n",
    "                raise ValueError('Wrong choice of transition.')\n",
    "            if opt.add_transition_rules and 'id2label' in config:  # 0 is [PAD] label id, here remove it.\n",
    "                non_pad_id2label = copy.deepcopy(config['id2label']).__delitem__(0)\n",
    "                for k, v in non_pad_id2label.items():\n",
    "                    non_pad_id2label[k] = v - 1  # we 0 as [PAD] label id, here remove it.\n",
    "                constraints = allowed_transitions(constraint_type='BIO', labels=non_pad_id2label)\n",
    "            else:\n",
    "                constraints = None\n",
    "            decoder = ConditionalRandomField(\n",
    "                num_tags=transition_scorer.num_tags, constraints=constraints)  # accurate tags\n",
    "        else:\n",
    "            raise TypeError('wrong component type')\n",
    "    elif opt.task == 'mlc':  # for multi-label text classification task\n",
    "        grad_threshold = True if opt.threshold_type == 'learn' else False\n",
    "        if opt.decoder == 'mlc':\n",
    "            decoder = MultiLabelTextClassifier(opt.threshold, grad_threshold)\n",
    "        elif opt.decoder == 'eamlc':\n",
    "            decoder = EAMultiLabelTextClassifier(opt.threshold, grad_threshold)\n",
    "        elif opt.decoder == 'msmlc':\n",
    "            decoder = MetaStatsMultiLabelTextClassifier(opt.threshold, grad_threshold, meta_rate=opt.meta_rate,\n",
    "                                                        ab_ea=opt.ab_ea)\n",
    "        elif opt.decoder == 'krnmsmlc':\n",
    "            map_dict = {\n",
    "                \"feature_map\": opt.feature_map,\n",
    "                \"feature_num\": opt.feature_num,\n",
    "                \"feature_map_dim\": opt.feature_map_dim,\n",
    "                \"feature_map_act\": opt.feature_map_act,\n",
    "                \"feature_map_layer_num\": opt.feature_map_layer_num,\n",
    "            }\n",
    "            decoder = KRNMetaStatsMultiLabelTextClassifier(opt.threshold, grad_threshold, meta_rate=opt.meta_rate,\n",
    "                                                           ab_ea=opt.ab_ea, kernel=opt.kernel, bandwidth=opt.bandwidth,\n",
    "                                                           use_gold=opt.use_gold, learnable=opt.kernel_learnable,\n",
    "                                                           map_dict=map_dict)\n",
    "        else:\n",
    "            raise TypeError('wrong component type')\n",
    "    elif opt.task == 'sc':  # for single-label text classification task\n",
    "        decoder = SingleLabelTextClassifier()\n",
    "    else:\n",
    "        raise TypeError('wrong task type')\n",
    "\n",
    "    ''' Build the whole model '''\n",
    "    if opt.task == 'sl':\n",
    "        seq_labeler = SchemaFewShotSeqLabeler if opt.use_schema else FewShotSeqLabeler\n",
    "        model = seq_labeler(\n",
    "            opt=opt,\n",
    "            context_embedder=context_embedder,\n",
    "            emission_scorer=emission_scorer,\n",
    "            decoder=decoder,\n",
    "            transition_scorer=transition_scorer,\n",
    "            config=config,\n",
    "            emb_log=emb_log\n",
    "        )\n",
    "    elif opt.task in ['sc', 'mlc']:\n",
    "        text_classifier = SchemaFewShotTextClassifier if opt.use_schema else FewShotTextClassifier\n",
    "        model = text_classifier(\n",
    "            opt=opt,\n",
    "            context_embedder=context_embedder,\n",
    "            emission_scorer=emission_scorer,\n",
    "            decoder=decoder,\n",
    "            config=config,\n",
    "            emb_log=emb_log\n",
    "        )\n",
    "    else:\n",
    "        raise TypeError('wrong task type')\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as reader:\n",
    "            cpt = torch.load(reader, map_location='cpu')\n",
    "            model = make_model(opt=cpt['opt'], config=cpt['config'])\n",
    "            model = prepare_model(args=cpt['opt'], model=model, device=cpt['opt'].device, n_gpu=cpt['opt'].n_gpu)\n",
    "            model.load_state_dict(cpt['state_dict'])\n",
    "            return model\n",
    "    except IOError as e:\n",
    "        logger.info(\"Failed to load model from {} \\n {}\".format(path, e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理并行&device信息\n",
    "def prepare_model(args, model, device, n_gpu):\n",
    "    \"\"\" init my part parameter \"\"\"\n",
    "\n",
    "    \"\"\" Set device to use \"\"\"\n",
    "    if args.fp16:\n",
    "        model.half()\n",
    "    model.to(device)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                          output_device=args.local_rank)\n",
    "    elif n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
